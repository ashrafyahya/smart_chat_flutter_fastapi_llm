# smart_chatğŸ§© 1. ProjektÃ¼bersicht

Projekttitel: Smart Chat
Ziel: Erstellung eines komplett lokal laufenden Chat-Systems mit moderner UI, lokalem LLM-Backend und klarer Trennung zwischen Frontend und Backend.
Technologien:

    Frontend: Angular + UI-Framework (z.â€¯B. Angular Material oder Tailwind + Custom Components)

    Backend: Python (FastAPI), lokales LLM (z.â€¯B. llama.cpp, GPT4All, transformers mit quantisierten Modellen)

    Kommunikation: REST API (optional WebSocket fÃ¼r Streaming)

ğŸ“‹ 2. Anforderungen (funktional & nicht-funktional)
ğŸ”· Frontend (Angular)
Funktionale Anforderungen:

    Chatfenster mit Nachrichtenein- und -ausgabe

    Historie von Konversationen

    Ladeindikator, wenn das Modell antwortet

    Fehleranzeige bei Backend-Problemen

    Eingabefeld mit "Senden"-Button + Enter-Key Support

    Responsives Design (mobilfÃ¤hig)

Erweiterungen (spÃ¤ter mÃ¶glich):

    Rollenwechsel (User / System / Assistant)

    Konversationsverwaltung (lÃ¶schen, speichern, umbenennen)

    Theme-Switch (hell/dunkel)

    Spracheinstellungen

ğŸ”¶ Backend (Python)
Funktionale Anforderungen:

    REST-API fÃ¼r Chat-Endpunkt (/api/chat)

    Integration eines lokalen LLM:

        Einfaches Modell fÃ¼r schnellen Start: z.â€¯B. ggml, llama.cpp, GPT4All, mistral quantisiert

    Optional: Session-Verwaltung (fÃ¼r ChatverlÃ¤ufe)

    Logging von Fehlern und Anfragen

    Einfache Konfigurationsdatei (config.yaml oder .env)

    CORS aktivieren fÃ¼r Angular-Kommunikation

Erweiterungen:

    WebSocket-Support (Streaming)

    Mehrere Modelle unterstÃ¼tzen

    API-Key-basierte Authentifizierung

ğŸ› ï¸ 3. Software & Tools (lokal installieren)
ğŸ”§ Frontend
Tool	Zweck
Node.js	Runtime fÃ¼r Angular
Angular CLI	Projektverwaltung, Build, Serve
UI-Framework	z.â€¯B. Angular Material, Tailwind CSS
VSCode Extensions	Angular Essentials, ESLint, Prettier, etc.
Installationsbefehle:

```bash 
npm install -g @angular/cli 
ng new smart-chat-frontend
cd smart-chat-frontend
ng add @angular/material
```

ğŸ Backend
Tool	Zweck
Python 3.10+	Laufzeitumgebung
FastAPI	API-Framework
uvicorn	ASGI Server
httpx / requests	Optionale HTTP-Clients
LLM-Wrapper	z.â€¯B. llama-cpp-python, transformers
Virtualenv	fÃ¼r isolierte Umgebungen
Installationsbefehle:
```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
pip install fastapi uvicorn python-dotenv
# Optional je nach Modell
pip install llama-cpp-python
pip install transformers
```

ğŸ“ 4. Projektstruktur (Vorschlag)
ğŸ“¦ Gesamtstruktur
smart-chat/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ chat.py
â”‚   â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”‚   â””â”€â”€ llama_wrapper.py
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ smart-chat-frontend/
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ app/
â”‚       â”‚   â”‚   â”œâ”€â”€ chat/
â”‚       â”‚   â”‚   â””â”€â”€ shared/
â”‚       â””â”€â”€ angular.json
â””â”€â”€ README.md


